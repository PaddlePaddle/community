# Science 53 设计文档 

> RFC 文档相关记录信息

|              |                    |
| ------------ | -----------------  |
| 提交作者      |xiaoyewww             |
| 提交时间      |2025-03-17          |
| RFC 版本号    | v1.0               |
| 依赖飞桨版本  | develop            |
| 文件名        |hackthon8th_16_data_efficient_nopt.md   |

## 1. 概述

### 1.1 相关背景

> data_efficient_nopt旨在提高偏微分方程（PDE）算子学习的数据效率，通过设计无监督预训练方法减少对高成本模拟数据的依赖。利用未标记的PDE数据（无需模拟解），并通过基于物理启发的重建代理任务对神经算子进行预训练。为了提升分布外（OOD）泛化性能，我们进一步引入了一种基于相似性的上下文学习方法，使神经算子能够灵活利用上下文示例，而无需额外的训练成本或设计。在多种PDE上的实验表明，该方法具有高度的数据效率、更强的泛化能力，甚至优于传统的视觉预训练模型。

### 1.2 功能目标

> 在本任务中，作者根据[Data-Efficient Operator Learning via Unsupervised Pretraining and In-Context Learning
](https://arxiv.org/abs/2402.15734)中的[代码](https://github.com/delta-lab-ai/data_efficient_nopt)
>
> 复现data_efficient_nopt训练推理。

### 1.3 意义

> 这篇论文主要解决使用深度学习方法解决基于偏微分方程（PDEs）的科学问题时的数据效率问题。具体来说，作者指出当前的神经算子（Neural Operators）方法需要大量的高保真PDE数据，这导致了高昂的数值模拟成本。为了减少对这些昂贵数据的依赖，作者提出了一种无监督预训练方法，旨在通过使用无标签的PDE数据来提高模型的数据效率和泛化能力。

> 论文通过以下方案解决上述提到的问题：

    1. 无监督预训练
        - 无标签PDE数据定义：作者定义了无标签的PDE数据，这些数据不包含PDE的解，从而避免了昂贵的数值模拟。
        - 物理启发的代理任务：作者提出了两个基于重构的代理任务，分别是Masked Autoencoder（MAE）和Super-resolution（SR）。MAE通过随机遮蔽部分输入并要求模型重建完整的输入来学习稀疏感知的不变性；SR通过应用高斯滤波器使输入模糊，然后要求模型重建高分辨率的输入来学习分辨率和模糊的不变性。
        - 预训练过程：使用无标签的PDE数据和上述代理任务进行无监督预训练，从而获得更好的初始模型，减少后续监督训练所需的模拟数据量。

    2. 上下文学习
        - 相似性挖掘：在推理时，通过计算查询输入与支持示例（demos）的输出距离来找到相似的示例。
        - 聚合预测：对于每个查询的时空位置，找到相似的示例后，通过聚合这些示例的解来生成最终的预测。
        - 方法优势：这种方法在推理时引入了零额外训练成本，而且可以无缝集成到现有的训练管道中，提高了模型在OOD数据上的泛化能力。

> 需要进一步探索的点，包括局限性和未来研究方向

    1. 设计更多的物理启发代理任务和数据增强方法：当前的方法主要使用MAE和SR，但可以探索更多与物理相关的代理任务和数据增强方法。
    2. 研究更多的PDE系统：虽然论文中已经研究了多个PDE系统，但可以进一步扩展到其他科学和工程领域中的PDE问题。
    3. 考虑不同的神经算子架构：当前研究主要集中在FNO和Transformer架构上，可以考虑其他类型的神经算子架构，以验证方法的普适性。

> 综上，这篇论文旨在提高使用深度学习解决偏微分方程（PDEs）问题时的数据效率。作者提出了无监督预训练和上下文学习（ICL）两种方法。无监督预训练通过使用无标签的PDE数据和物理启发的代理任务（如Masked Autoencoder和Super-resolution）来减少对昂贵模拟数据的依赖，从而提高数据效率和模型泛化能力。上下文学习在推理时通过提供少量的上下文示例（demos）来进一步提高模型在未见过的物理参数下的泛化能力，且不增加额外的训练成本。通过广泛的实验评估，作者展示了这些方法在多个PDE基准数据集和真实世界数据集上的有效性和优势，为科学和工程领域的数据驱动建模提供了新的思路。

## 2. PaddleScience 现状

> PaddleScience目前没有该模型的实现。

## 3. 目标调研

复现data_efficient_nopt模型训练和推理，精度与论文中对齐。

## 4. 设计思路与实现方案

参考 Paddle 与 PyTorch API 转换文档，将 PyTorch 中对应的 API进行改写。 

## 5. 测试和验收的考量

1. 通过 PaddleScience 的代码风格检查
2. data_efficient_nopt训练推理精度与论文中对齐

## 6. 可行性分析和排期规划

1. 提交RFC 25年3月
2. 完成PR合入 25年4月

## 7. 影响面

无。