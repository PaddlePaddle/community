# 标题

|任务名称 | xxx                                   | 
|---|---------------------------------------|
|提交作者<input type="checkbox" class="rowselector hidden"> | XULingWYY                             | 
|提交时间<input type="checkbox" class="rowselector hidden"> | 2025-4-21                             | 
|版本号 | V1.0                                  | 
|依赖飞桨版本<input type="checkbox" class="rowselector hidden"> | develop                               | 
|文件名 | 20250421_wgan_gp.md<br> | 

# 一、概述
## 1、相关背景
- 生成对抗网络（GANs）是强大的生成模型，但存在训练不稳定的问题。
- Wasserstein GAN（WGAN）在稳定 GAN 训练方面取得了进展，但有时仍可能仅生成低质量样本或无法收敛。这些问题通常源于 WGAN 中通过权重截断（weight clipping）对评判器（critic）施加 Lipschitz 约束，而这可能导致不良行为。 
- Improved Training of Wasserstein GANs(WGAN-GP)提出一种替代权重截断的方法：对评判器输入相关的梯度范数施加惩罚。方法优于标准 WGAN
- https://github.com/PaddlePaddle/Paddle/issues/71310
## 2、功能目标
- 在paddlescience中实现WGAN-GP模型

## 3、意义
- 丰富paddlescience中GAN模型库，提升模型训练稳定性。

# 二、飞桨现状
- paddlescience目前的GAN模型库中，没有实现WGAN-GP模型。


# 三、业内方案调研
- TensorFlow实现
https://github.com/igul222/improved_wgan_training
- PyTorch实现
https://github.com/jalola/improved-wgan-pytorch

# 四、对比分析
- TensorFlow实现的WGAN-GP代码老旧不支持python3
- PyTorch实现的WGAN-GP代码较为复杂，需要大量修改才能适配paddlepaddle框架

# 五、设计思路与实现方案

## 1、主体设计思路与折衷
### 整体全貌
- Generator模型
- Discriminator模型
- Loss函数
### 主体设计具体描述
- Generator模型
```python
optimized_resblock_disc1 = OptimizedResBlockDisc1(dim)
ResidualBlocks=nn.LayerList([ResidualBlock(dim, dim, 3, resample='down', normalize_mode="Discriminator",
                                                use_label=use_label,ln1_size=16,ln2_size=16),
                                  ResidualBlock(dim, dim, 3, resample=None, normalize_mode="Discriminator",
                                                use_label=use_label,ln1_size=8,ln2_size=8),
                                  ResidualBlock(dim, dim, 3, resample=None, normalize_mode="Discriminator",
                                                use_label=use_label,ln1_size=8,ln2_size=8),
                     ])
relu = Nonlinear()
linear = nn.Linear(dim, 1)
linear2= nn.Linear(dim, 10)
```
- Discriminator模型
```python
linear1 = nn.Linear(128, 4 * 4 * dim)
ResidualBlocks=nn.LayerList([ResidualBlock(dim, dim, 3, resample='up', normalize_mode="Generator",
                                                use_label=use_label, ),
                                  ResidualBlock(dim, dim, 3, resample='up', normalize_mode="Generator",
                                                use_label=use_label),
                                  ResidualBlock(dim, dim, 3, resample='up', normalize_mode="Generator",
                                                use_label=use_label),
                     ])
Normalize = Normalize(dims=dim, mode="Generator", label=False)
relu = Nonlinear()
conv = nn.Conv2D(in_channels=dim, out_channels=3, kernel_size=3, padding='same')
tanh = nn.Tanh()

```
- Loss函数
 - Generator Loss
```python
gen_cost = -paddle.mean(disc_fake)

```
 - Discriminator Loss
```python
disc_cost = disc_cost + gradient_penalty + (acgan_scale * disc_acgan)

```
### 主体设计选型考量
- WGAN-GP源代码 https://github.com/igul222/improved_wgan_training
- WGAN-GP的论文

# 六、测试和验收的考量
## 1、测试策略
- IS分数
## 2、验收标准
- 与论文结果相差10%以内
  - Unsupervised WGAN-GP ResNet 7.86 ± 0.786
  - Supervised WGAN-GP ResNet 8.42 ± 0.842

# 七、影响面
- 丰富paddlescience中GAN模型库，提升模型训练稳定性。

## 对用户的影响
- 用户可在paddlescience中直接使用WGAN-GP模型。

## 对二次开发用户的影响
- 二次开发用户可参考WGAN-GP模型进行二次开发。

# 八、排期规划
总体开发周期预计为 4 周，具体排期如下：

### 第 1 周：核心算法实现
- 实现 WGAN-GP 的基本框架
- 实现梯度惩罚计算
- 实现损失函数和训练循环

### 第 2 周：完成模型训练
- Unsupervised WGAN-GP ResNet 训练
- Supervised WGAN-GP ResNet 训练

### 第 3 周：评估和优化
- 实现IS评估指标
- 与论文进行性能对齐

### 第 4 周：集成和文档
- 编写文档和示例
- 进行最终测试和调整


# 名词解释
- WGAN-GP：Improved Training of Wasserstein GANs
- GAN：生成对抗网络
- WGAN：Wasserstein GAN
- IS：Inception Score

# 附件及参考资料
- [Improved Training of Wasserstein GANs](https://arxiv.org/abs/1704.00028)
