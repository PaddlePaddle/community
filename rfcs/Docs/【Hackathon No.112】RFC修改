# 飞桨文档体验方案

|领域 | 飞桨文档体验方案 | 
|---|---|
|提交作者<input type="checkbox" class="rowselector hidden"> | mkm wjc | 
|提交时间<input type="checkbox" class="rowselector hidden"> | 2022-03-30 | 
|版本号 | V1.0 | 
|依赖飞桨版本<input type="checkbox" class="rowselector hidden"> | paddlepaddle-gpu==2.2 | 
|文件名 | 20220320_docs_eval_docs.md<br> | 


# 一、概述
## 1、相关背景

飞桨框架于 2.0 正式版全面支持了动态图训练，并在2.1、2.2 两个大版本中不断完善分布式能力，同时大幅增强了训练功能。需要进行飞浆动态图分布式训练的评估。

## 2、功能目标

根据文档示例，体验分布式训练相关功能，包括但不限于：在Fleet API使用、分布式动态图训练、环境配置、报错查错、性能调优、文档质量等方面，反馈使用体验。

## 3、意义

从用户角度体验飞桨分布式框架，发掘文档体系中可以改善的功能点。

# 二、飞桨现状

飞桨从 [2.0.0](https://github.com/PaddlePaddle/Paddle/releases/tag/v2.0.0) 从 1.x 到 2.0 做了较大的功能更新。对应的文档，也随着做出了较大的改动。

[飞桨的文档](https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/index_cn.html) 显式遵循了 https://documentation.divio.com/ 所描述的文档体系。这与 [MindSpore](https://www.mindspore.cn/) 类似。与 [PyTorch](https://pytorch.org/docs/stable/index.html) 不同。这在用户体验上各有特色，给用户不同的感受。

在本次黑客松之前，未见有人发起对飞桨 2.0 之后的文档做充分分析并生成体验报告。

# 三、业内方案调研

Pytorch目前支持分布式训练，其API包括torch.nn.parallel.DataParallel与torch.nn.parallel.DistributedDataParallel，两个API都属于数据并行。
DataParallel和DistributedDataParallel有如下不同：
    DataParallel是单进程，多线程的并行训练方式，并且只能在单台机器上运行。
    DistributedDataParallel是多进程，并且适用于单机和多机训练。DistributedDataParallel数据并行的效率比DataParallel数据并行的效率高。

paddle 使用的分布式框架的Fleet API 该 API支持动态图编译以及静态图编译。

# 四、设计思路与实现方案

对比pytorch框架以及飞浆分布式并行框架的运行速度，识别准确的度，分析两个框架使用的难易程度，使用方式。（具体查看第五点实现方案）

环境配置
（1）在曙光超算昆山计算服务器部署pytorch分布式环境，给出部署步骤（已经完成）
（2）在曙光超算昆山计算服务器部署paddle分布式环境，给出部署步骤（已经完成）
（3）对比两者的易用性与区别

文档质量
（1）寻找pytorch分布式文档，对其进行分析
（2）分析运行paddle官方给出的分布式文档例子，给出文档中代码或者其他方面的不足。（目前发现一个不足点）
（3）对比（1）（2）

Fleet API的使用
（1）分析pytorch分布式框架DDP某些API的使用（已经完成）
（2）按照文档内容使用Fleet API（已经完成）
（3）1和2之间的使用体验对比

分布式动态图训练
（1）使用pytorch完成一个图像分类的动态图分布式例子，给出分析（即将完成）
（2）使用paddle完成一个图像分类的分布式例子，给出分析（已经完成）完成单机多卡的实现，由于曙光超算的环境问题，目前暂时无法实现曙光上多机多卡的分布式例子。
（3）分析两者程序上运行结果。

报错查错（错误汇总）
（1）	在曙光超算昆山计算服务器部署paddle环境时出现的报错并分析给出解决方案
（2）	分析在运行paddle文档分布式代码时出现的错误，并给出解决方案


# 五、可行性分析和排期规划

对各Pytorch分布式训练框架ddp已经有一定了解，之后需要对比ddp和飞浆分布式框架之间的不同，进一步做细致的体验测试及分析。形成详细的报告文档。
已经完成一份评估文档，以及完成了pytorch和paddlepaddle的分布式训练。


