from typing import Any, Callable

import jax
from flax import linen as nn

from .nn import NN
from .. import activations
from .. import initializers


class FNN(NN):
    """Fully-connected neural network"""

    layer_sizes: Any
    activation: Any
    kernel_initializer: Any
    training: bool = True
    _input_transform: Callable = None
    _output_transform: Callable = None
    params: Any = None

    def setup(self):
        # TODO: implement get regularizer
        self._activation = activations.get(self.activation)
        kernel_initializer = initializers.get(self.kernel_initializer)
        initializer = jax.nn.initializers.zeros

        self.denses = [
            nn.Dense(
                unit,
                kernel_init=kernel_initializer,
                bias_init=initializer,
            )
            for unit in self.layer_sizes[1:]
        ]

    def __call__(self, inputs, training=True):
        x = inputs
        if self._input_transform is not None:
            x = self._input_transform(x)
        for linear in self.denses[:-1]:
            x = self._activation(linear(x))
        x = self.denses[-1](x)
        if self._output_transform is not None:
            x = self._output_transform(inputs, x)
        return x
