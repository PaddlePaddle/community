# Logsumexp OPæ€§èƒ½ä¼˜åŒ–è®¾è®¡æ–‡æ¡£


| åŸºæœ¬ä¿¡æ¯                                                     | å†…å®¹                                   |
| ------------------------------------------------------------ |--------------------------------------|
| æäº¤ä½œè€…<input type="checkbox" class="rowselector hidden">   | thunder95                            |
| æäº¤æ—¶é—´<input type="checkbox" class="rowselector hidden">   | 2023-03-26                           |
| ç‰ˆæœ¬å·                                                       | V1.0                                 |
| ä¾èµ–é£æ¡¨ç‰ˆæœ¬<input type="checkbox" class="rowselector hidden"> | PaddleDevelop                        |
| æ–‡ä»¶å                                                       | 20230326_logsumexp_op_optimization.md<br> |


# 1 èƒŒæ™¯ä¸æ„ä¹‰

ç›®å‰ Paddle å†… logsumexp ç®—å­ GPU è®¡ç®—é‡‡ç”¨äº†Eigenåº“å®ç°ï¼Œæ€§èƒ½ä»æœ‰æ˜æ˜¾çš„æå‡ç©ºé—´ã€‚

## 1.1 é£æ¡¨ç°çŠ¶

å½“å‰æ€§èƒ½å¦‚ä¸‹è¡¨(åŸºäºPaddlePaddleã€€developåˆ†æ”¯)ï¼š

ç›®å‰çš„å®ç°æœ‰ä¸€å®šçš„æ€§èƒ½ä¼˜åŒ–ç©ºé—´ï¼Œå¯ä»¥åŠ å…¥ä¸€äº›æ€§èƒ½ä¼˜åŒ–çš„æŠ€å·§ã€‚å½“å‰forwardæ€§èƒ½å¦‚ä¸‹è¡¨ï¼š

| Case No. | device | input_shape | input_type | Paddle Perf(ms) |
|---|---|---|---|---|
| 1 | RTX 2070s | [64L, 64L] | float32 | 0.0681 | 
| 2 | RTX 2070s | [1024L, 512L] | float32 | 0.67155 |
| 3 | RTX 2070s | [64L, 64L] | float16 | 0.06718 |
| 4 | RTX 2070s | [1024L, 512L] | float16 | 0.64455 |


APIæ–‡æ¡£ https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/logsumexp_cn.html

## 1.2 ä¸šå†…æ–¹æ¡ˆè°ƒç ”

Pytorchä¸­APIæ–‡æ¡£ï¼šã€€https://pytorch.org/docs/1.12/generated/torch.logsumexp.html?highlight=logsumexp#torch.logsumexp

Pytorchä¸­sum_outå¯åŸºäºcudaè®¡ç®—, forwardæ•´ä½“æ€§èƒ½å¦‚ä¸‹(åŸºäºpytorchã€€v1.12)ï¼š

| Case No. | device | input_shape | input_type | Pytorch Perf(ms) |
|---|---|---|---|---|
| 1 | RTX 2070s | [64L, 64L] | float32 | 0.03757 | 
| 2 | RTX 2070s | [1024L, 512L] | float32 | 0.05742 |
| 3 | RTX 2070s | [64L, 64L] | float16 | 0.04035 |
| 4 | RTX 2070s | [1024L, 512L] | float16 | 0.05294 |

## 1.3 å¯¹æ¯”åˆ†æ

ç›®å‰Paddleä¸Pytorchçš„APIè®¾è®¡æ–¹æ¡ˆç›¸ä¼¼ï¼Œ4ç§caseä¸‹æµ‹è¯•Pytorchæ€§èƒ½æ›´ä¼˜,
äºŒè€…ä¸»è¦å·®åˆ«æ˜¯Paddleé‡‡ç”¨çš„æ˜¯Eigenæ–¹å¼è®¡ç®—ï¼ŒğŸ•‘ç„¶è€ŒPytorchä¸­åŸºäºcudaå¯æ˜æ˜¾æå‡æ€§èƒ½ã€‚

pytorchä¸­ä¸»è¦å®ç°ä»£ç ï¼š

```c++
static Tensor& logsumexp_out_impl(Tensor& result, const Tensor& self, IntArrayRef dims, bool keepdim) {
  // can't take max of empty tensor
  if (self.numel() != 0) {
    auto maxes = at::amax(self, dims, true);
    auto maxes_squeezed = (keepdim ? maxes : squeeze_multiple(maxes, dims));
    maxes_squeezed.masked_fill_(maxes_squeezed.abs() == INFINITY, 0);
    at::sum_out(result, (self - maxes).exp_(), dims, keepdim);
    result.log_().add_(maxes_squeezed);
  } else {
    at::sum_out(result, at::exp(self), dims, keepdim);
    result.log_();
  }
  return result;
}
```
# 2 è®¾è®¡æ–¹æ¡ˆä¸æ€§èƒ½é¢„æœŸ

## 2.1 å…³é”®æ¨¡å—ä¸æ€§èƒ½æå‡ç‚¹

åŸºäºPaddleä¸­å·²å°è£…å¥½çš„ReduceåŠElementwiseï¼ŒäºŒè€…å……åˆ†åˆ©ç”¨äº†å‘é‡åŒ–è¯»å†™æ“ä½œçš„ä¼˜ç§€æ€§èƒ½ï¼Œå·²åšäº†åˆæ­¥æµ‹è¯•ï¼Œä¼˜åŒ–çš„æ€§èƒ½èƒ½å¤Ÿè¶…å‡ºé¢„æœŸã€‚

## 2.2 Hostç«¯è®¡ç®—æµç¨‹

è®¡ç®—reduceçš„axisï¼Œkeepdimç­‰ï¼Œè°ƒç”¨reduceç®—å­å°è£…å¥½çš„æ¥å£ã€‚

## 2.4 Deviceç«¯è®¡ç®—æµç¨‹

åŸºäºç°æœ‰çš„kpsç®—å­è¿›è¡Œç»„è£…å³å¯ã€‚

# 3 æµ‹è¯•å’ŒéªŒæ”¶çš„è€ƒé‡

å‚è€ƒï¼š[ç®—å­æ€§èƒ½ä¼˜åŒ–éªŒæ”¶æ ‡å‡†](http://agroup.baidu.com/paddle-perf/md/article/4892913)

# 4 å¯è¡Œæ€§åˆ†æå’Œæ’æœŸè§„åˆ’

æ—¶é—´å’Œå¼€å‘æ’æœŸè§„åˆ’ï¼Œä¸»è¦milestone

| No. | å¼€å‘å†…å®¹ | é¢„æœŸæ—¶é—´ |
|---|---|---|
| 1 | ç†æ¸…Paddleä¸­OPè®¾è®¡æ€è·¯ï¼ŒåŒç±»äº§å“ä¸­æœ€ä½³è®¾è®¡æ–¹æ¡ˆ  | 2023-03-26 |
| 2 | å®Œæˆå¼€å‘æ–‡æ¡£è®¾è®¡  | 2023-03-26 |
| 3 | logsumexpä¼˜åŒ–å®ç°  | 2023-03-26 |
| 3 | å®Œæˆä»£ç å¼€å‘å·¥ä½œï¼Œå¹¶é€šè¿‡çº¿ç¨‹CIæµ‹è¯• | 2023-03-31 |



# 5 å½±å“é¢

å¾…ä¼˜åŒ–çš„ç®—å­ç‹¬ç«‹è¿è¡Œï¼Œä¸æ¶‰åŠå…¶ä»–ç®—å­å’Œæ¨¡å—çš„ä¿®æ”¹ï¼ŒAPIè®¾è®¡ä¸ä¹‹å‰ä¿æŒä¸€è‡´ã€‚


# åè¯è§£é‡Š


# é™„ä»¶åŠå‚è€ƒèµ„æ–™

[1]. [OP Benchmarkä½¿ç”¨æŒ‡å—](https://github.com/PaddlePaddle/benchmark/blob/master/api/README.md)


