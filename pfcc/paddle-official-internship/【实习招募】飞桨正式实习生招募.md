此文档展示 **【实习招募】飞桨正式实习生招募（长期 / 高强度 / 高含金量项目）**- 项目的详细介绍

## 赛题详情

### 课题一：面向大模型训练的高效分布式checkpoint系统研究

#### 项目介绍：

Checkpoint系统用于持久化保存模型参数、优化器、数据流、随机数等状态，以便训练任务发生故障时能够进行状态恢复。在模型预训练、后训练及推理等不同阶段衔接过程中，分布式策略和模型网络结构的实现差异会导致模型权重的分布状态发生变化，为此需要进行checkpoint的转换和迁移。业内常见做法是针对不同模型和任务定制转换脚本，这种方法开发和维护成本高，代码难以复用，极大地影响大模型训推研发效率。飞桨的分布式checkpoint系统基于统一的切分标记与参数重组描述，可灵活支持跨分布式策略和跨模型结构间的参数自动重切分，大幅降低权重转换成本。本课题学员将参与到飞桨分布式checkpoint系统的性能优化工作中，包括但不限于chcekpoint系统核心模块的代码开发和功能完善，分布式通信效率优化，文件系统读写性能优化等。

#### 学员要求（1 人）：

- 熟悉 Python和C++，有较强的编程和调试能力。
- 熟悉 NCCL通信库，有并行计算、分布式计算相关经验。
- 熟悉 Paddle、PyTorch和Megatron等训练框架。
- 熟悉操作系统及常见文件系统的设计原理。

### 项目二：大模型训练策略自动寻优系统研发

#### 项目介绍：

近年来，针对大模型训练的分布式并行策略和优化技术日趋多样，但特定任务下并行模式和优化策略的组合配置极大依赖于专家经验，且定制化的配置结果在模型结构、参数规模、硬件环境等发生变化时难以迁移。本课题学员将参与开发大模型训练策略的自动配置和寻优工具（AutoTuner），通过合理的搜索空间设计及高效的搜索算法和剪枝策略，为用户提供一套通用的模型自动化配置解决方案。工作内容包括但不限于：
- 全面的搜索空间设计：针对数据并行、模型并行、专家并行、序列并行、流水并行等主流的大模型并行策略，设计多个搜索维度，自动分析和构建全面而灵活的搜索空间。
- 搜索算法与剪枝实现：调研并实现先进的搜索算法，支持用户快速搜索，同时开发高效的剪枝策略，基于历史结果和先验剪枝规则减少不必要的搜索次数，提高搜索效率。
- 性能与代价模型建模：针对不同硬件特性，建模训练任务对计算、通信和存储等资源的占用开销及性能状况，用于在搜索过程中快速评估配置性能并过滤不合法的配置，同时利用实测性能数据训练模型，提高配置评估的准确性和高效性。
- 用户友好的界面设计：提供清晰易用的配置接口，使用户无需修改模型代码即可实现自动寻优功能，同时集成到主流的云服务管理平台，通过一键式开关帮助用户实现全自动分布式训练，达到卡时节省的目的。

#### 学员要求（1 人）：

- 熟悉 Python和C++，有扎实的编程基础。
- 具备较强的算法和数据结构能力。
- 熟悉Megatron等分布式训练框架。
- 了解常见的大模型并行策略及优化技术。

### 项目三：大模型低资源训练能力与优化策略研究

#### 项目介绍：

随着大模型参数规模的持续增长，其全量预训练与微调过程对计算资源、存储资源和时间成本提出了极高的要求，极大地限制了广大研究机构与企业在资源受限环境下的技术创新与应用落地。如何在有限的GPU内存、计算卡数和训练时长等约束下，高效地完成大模型的训练与适配，已成为当前产业界与学术界关注的焦点。本课题旨在系统性地研究并整合前沿的低资源训练与优化技术，构建一套智能、高效的分布式训练加速与资源节省系统，通过算法与工程的协同优化，在有限硬件资源下实现大模型的高效训练。

#### 学员要求（1 人）：

- 熟悉Python和C++，具备扎实的编程能力和系统调试经验。
- 熟悉深度学习框架（如PaddlePaddle, PyTorch）的基本原理和机制，有模型训练或调优经验者优先。
- 对大模型相关技术有浓厚兴趣，了解参数高效微调、模型量化、混合精度训练、分布式训练等其中至少一项技术。
- 具备强烈的责任心、良好的团队协作能力和主动学习精神。

### 课题四：分布式自动并行切分推导模块的全面升级与优化

#### 项目介绍：

切分推导模块作为自动并行技术的核心组件，扮演着至关重要的角色。它能够依据少量张量的分布式状态信息，精准推导出其他张量与算子的分布式切分状态，进而自动实现高效分布式训练。然而，随着大模型技术的迅猛发展，现有的切分推导模块在支持多样化分布式并行训练策略方面已显力不从心。因此，本项目旨在对该模块进行系统性升级，以达成以下目标：
1. 高度可扩展性：构建模块化、易扩展的架构，使开发人员能够迅速为批量算子开发切分推导规则，加速新功能的迭代。
2. 多场景覆盖：确保模块能够快速适配各种分布式并行策略，为模型的高效迭代提供坚实支撑，满足不同场景下的训练需求。
3. (可选) 极致性能优化：推导出在最优性能条件下的分布式状态，提升训练性能。

#### 学员要求（1 人）：

- 熟悉 Python和C++，有扎实的编程基础，了解常见的大模型并行策略及优化技术。
- 对大模型技术有浓厚兴趣，有较强的学习、沟通、问题解决能力。
- 实习3个月及以上，确保有足够时间深度参与项目。

### 课题五：FlashAttention 低精度训练算法研究与 Kernel 开发

#### 项目介绍：

在基于 Transformer 架构的大型语言模型（LLM）和多模态视觉语言模型（VLM）中，Attention 机制的计算开销随序列长度呈二次方增长，成为模型长文训练和推理的主要瓶颈。尽管 DeepSeek 已经端到端验证了 FP8 精度训练的可行性，但其优化主要集中在 Linear 层，而 Attention 算子的低精度训练仍有较大研究空间。
本项目旨在深入研究并实现支持 FP8/FP4 低精度的 Attention 算法，结合 Hopper 和 Blackwell 等最新 GPU 架构，针对硬件特性进行极致性能优化。项目将开发高效的 FlashAttention Kernel，系统性地验证低精度下 Attention 的收敛性与精度表现，推动大模型训练的高效化和低成本化，加速业界在大规模模型训练领域的创新步伐。

#### 营员要求（1 人）：

- 具备CUDA Kernel 优化经验
- 具备大模型训练的经验/论文发表经验
- 了解低精度计算
- 可实习 6个月以上的硕士生/博士生

### 课题六：面向通信计算融合的AI编译器关键技术研究

#### 项目介绍：

在大规模语言模型（LLM）、多模态模型等分布式AI任务中，通信开销（如参数同步、梯度传输）与计算开销（如矩阵乘、注意力计算）的分离架构已成为性能瓶颈——但传统AI编译器多聚焦于计算图优化或单设备性能提升，在通信与计算的协同调度方面相关工作还处于探索阶段。
本项目旨在设计面向通信计算融合的下一代AI编译器，通过编译层联合优化实现通信与计算的时空重叠，具体包括：
通信计算联合中间表示（IR）设计，统一建模计算算子与通信原语的依赖关系；DSL 接口的设计与对接；生成Kernel自动调优等。本项目研究课题较为前沿，有一定难度，欢迎感兴趣且喜欢挑战的同学参与。

#### 学员要求（2 人）：

- 有CUDA/Triton Kernel开发、优化经验，对GPU等硬件架构有基本认知，具备性能分析与优化实践能力
- （加分项）有AI编译器相关开发经验（如Triton/TileLang/MLIR/TVM/XLA 等），了解编译流程、中间表示优化及代码生成

### 课题七：飞桨核心算子精度与性能攻坚

#### 项目介绍：

在人工智能迈向大规模工业化应用的关键阶段，深度学习框架的核心算力（Kernel）是决定上层模型效能与边界的基石。本课题将引领你深入飞桨（PaddlePaddle）框架的核心层，直面大模型训练与科学计算等前沿领域对计算精度、性能及效率的极限挑战。你将直接参与优化核心算子的数值稳定性与计算性能，设计创新的融合算子（Fused Kernel）以突破内存与带宽瓶颈，并推动其在新硬件与先进算法上的高效适配。我们诚邀有志于掌握系统底层技术与推动计算前沿的你，共同参与这个课题。

#### 学员要求（2 人）：

- 有CUDA Kernel开发、优化经验
- 对深度学习基本理论有一定了解

### 课题八：基于国产GPU卡的大模型适配技术

#### 项目介绍：

百度飞桨（Paddle）作为原生支持多硬件后端的深度学习框架，已迭代升级多版CustomDevice方案，可兼容接入类CUDA硬件及各类ASIC，且类CUDA硬件的Kernel复用率达92.6%。目前PaddleFormers仓库中已涵盖ERNIE、Qwen、Deepseek、GPT、Gemma等系列主流大模型，支持LoRA、SFT、DPO等多种后训练方案——这些模型在GPU上已具备良好性能与优异表现，借助Paddle多硬件统一接口方案，可快速迁移至其他国产硬件。
本项目可学习业内最新开源模型的架构与并行策略，将其迁移至国产GPU卡，研究大模型后训练技术及优化方案，掌握大模型在国产GPU上的优化策略。目前我们已具备成熟的大模型迁移适配方案与路径，可快速实现模型跨硬件平台复现。

#### 学员要求（3 人）：

- 熟悉 Python和C++，有扎实的编程基础，了解CUDA Kernel开发
- 对大模型训练有一定了解
- 了解常见的大模型并行策略及优化技术。

### 课题九：⾯向深度学习计算图的智能化编译器系统研究

#### 项目介绍：

本项目旨在构建面向深度学习计算图的智能化编译器系统（AI4C），以大模型为核心驱动引擎，突破传统编译器对人工规则和模板搜索的依赖，实现跨硬件平台的自动化编译优化与代码生成。项目涵盖大规模计算图数据集（GraphNet）构建、智能体驱动的编译优化、时空张量（TST）编程范式设计等核心模块，支撑未来更大规模深度学习模型的高效执行。现阶段研究重点包括：
- 基于大模型的智能体自主生成图优化策略、调度配置及高性能Kernel代码。
- 探索跨硬件架构的自动化编译优化技术，降低新硬件软件栈构建成本。
- 设计时空张量编程范式，简化内存访问下标计算，提升开发与调试效率。

#### 学员要求（4 人）：

- 具备扎实的Python、C++编程能力，熟悉Linux，具备问题分析与调试能力
- 了解深度学习框架（如PyTorch）的计算图结构与执行机制
- 对深度学习基本理论、对大模型训推流程有一定了解
- 熟悉MLIR、TVM、Triton等深度学习编译技术者优先